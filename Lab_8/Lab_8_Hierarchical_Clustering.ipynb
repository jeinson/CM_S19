{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering with Average Linkage\n",
    "In this lab we'll implement hierarchical clustering with average linkage. We'll be using data that looks like some kind of knowckoff MNIST data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import datasets\n",
    "from sklearn import manifold, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=10)\n",
    "X = digits.data[0:500,:]\n",
    "y = digits.target[0:500]\n",
    "n_samples, n_features = X.shape\n",
    "X_red = manifold.SpectralEmbedding(n_components=2).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray() \n",
    "plt.matshow(digits.images[4]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding up Hierarchical Clustering\n",
    "\n",
    "Now we're going to implement hierarchical clustering. I'm following some simple pseudo code from [Wikipedia](https://en.wikipedia.org/wiki/Single-linkage_clustering).\n",
    "\n",
    "The main algorithm is as follows\n",
    "\n",
    "1. Begin with the disjoint clustering having height h(0) = 0 and sequence number (algorithm iteration) m = 0.\n",
    "2. Find the most similar pair of clusters in the current clustering, say pair (r), (s), according to d[(r),(s)] = min d[(i),(j)] where the minimum is over all pairs of clusters in the current clustering.\n",
    "3. Increment the sequence number: m = m + 1. Merge clusters (r) and (s) into a single cluster to form the next clustering m. Set the height of this clustering to h(m) = d[(r),(s)] \n",
    "4. Update the distance matrix, D, by deleting the rows and columns corresponding to clusters (r) and (s) and adding a row and column corresponding to the newly formed cluster. The proximity between the new cluster, denoted (r,s) and old cluster (k) is defined as d[(k), (r,s)] = average d[(k),(r)], d[(k),(s)].\n",
    "5. If all objects are in one cluster, stop. Else, go to step 2. Alternatively you can also iterate for n-1 steps.\n",
    "\n",
    "You'll want to familiarize yourself with [cdist](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html) and [sets](https://docs.python.org/2/library/sets.html). I'll be using euclidean distance for my work and suggest you do as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fuseClusters(i, j, currentClusters):\n",
    "    \"\"\"\n",
    "    Description: Merges the two clusters located at index i and j in currentClusters. This should be\n",
    "        a rather short chunk of code (~1 line.)\n",
    "    Input: \n",
    "        i,j (int): Indices into currentClusters\n",
    "        currentClusters list(set()): A list of the current clusters at each step in clustering\n",
    "    Output:\n",
    "       clusterSet (set()): The merged clusters.\n",
    "    \"\"\"\n",
    "    assert clusterSetList[i].intersection(clusterSetList[j]) == set(), \"clusters with overlapping elements is fishy\"\n",
    "    # Your code here\n",
    "    clusterSet = \n",
    "    # End your code\n",
    "    assert len(clusterSet) > 1, \"You should not add any clusters of size 1.\"   \n",
    "    return(clusterSet)\n",
    "\n",
    "def calculateClusterDistances(X, clusterSetList, clusterIdx):\n",
    "    \"\"\"\n",
    "    Description: Calculates the distance between each cluster and the cluster at clusterIdx.\n",
    "        Uses average linking, but you could implement different linkage functions pretty easily.\n",
    "    Input: \n",
    "        X (np matrix): A matrix with observations over rows.\n",
    "        clusterSetList (list(set())): A list of sets where each set contains the cluster merged at step i.\n",
    "            From this list you can create many clusters depending on your cut height.\n",
    "        clusterIdx (int): Cluster wrt calculate the distance to for every other cluster.\n",
    "    Output:\n",
    "        clusterDistances (list): A list of distances of the cluster at clusterIdx to all other clusters.\n",
    "    \"\"\"\n",
    "    n = len(clusterSetList)\n",
    "    clusterDistances = [0]*n# where to store the distance of each cluster to clusterIdx\n",
    "    clusterIdxSubMat = X[list(clusterSetList[clusterIdx]), :]\n",
    "    # Calculate the distance between each cluster and the cluster at clusterIdx using average linkage.\n",
    "    # Your code here\n",
    "\n",
    "    # End your code\n",
    "    return(clusterDistances)\n",
    "\n",
    "\n",
    "\n",
    "def clusterSanityCheck(clusterSetList, n):\n",
    "    \"\"\"\n",
    "    Description: Performs a sanity check to make sure your clusters make sense. Checks that\n",
    "        each cluster exists only once in clusterSetList, and that the larger clusters occur at the\n",
    "        end of the list. You can ignore these errors by not using this function, but I think they should\n",
    "        be helpful.\n",
    "    Input: \n",
    "        clusterSetList (list(set())): A list of sets where each set contains the cluster merged at step i.\n",
    "            From this list you can create many clusters depending on your cut height.\n",
    "        n (int): The number of observations in the dataset\n",
    "    Output:\n",
    "        Not really important. Will error out if something is weird.\n",
    "        \n",
    "    \"\"\"\n",
    "    previousClusters = []\n",
    "    for i in range(n):\n",
    "        prevSet = set()\n",
    "        for clusterSet in clusterSetList:\n",
    "            if i == 0:\n",
    "                assert clusterSet not in previousClusters, \"cluster exists twice in cluster list\\n{}\".format(clusterSet)\n",
    "                previousClusters.append(clusterSet)\n",
    "            if i in clusterSet:\n",
    "                assert prevSet.issubset(clusterSet), \"element {} might occur in multiple sets\".format(i)\n",
    "                prevSet = clusterSet\n",
    "    return(True)\n",
    "\n",
    "\n",
    "\n",
    "def hclust(X):\n",
    "    \"\"\"\n",
    "    Description: Performs hierarchical clustering on the data in X. This follows the algorithm above\n",
    "        pretty closely\n",
    "    Input: \n",
    "        X (np matrix): A matrix with observations over rows.\n",
    "    Output:\n",
    "        clusterSetList (list(set())): A list of sets where each set contains the cluster merged at step i.\n",
    "            From this list you can create many clusters depending on your cut height.\n",
    "        clusterHeightList (list(float)): A list of floats. Each value is the height that each cluster was \n",
    "            merged at.\n",
    "    \"\"\"\n",
    "    n, m = X.shape\n",
    "    infDiag = np.zeros((n, n), float)# this will come in handy so the algorithm doesn't keep choosing \n",
    "    # to merge the same elements over and over because of their distance along the diagonal.\n",
    "    np.fill_diagonal(infDiag, np.inf)\n",
    "\n",
    "    \n",
    "    # we want to hold on to two lists. A list of sets representing the clusters at each iteration\n",
    "    # and a list of ints representing the height that each cluster was merged at.\n",
    "    \n",
    "    singleClusterSetList = [set([x]) for x in range(n)]# the single element clusters\n",
    "    singleClusterSetList.extend([set()]*(n-1))# a list containing the most recent cluster at each step\n",
    "    clusterSetList = singleClusterSetList\n",
    "\n",
    "    singleClusterHeight = [0 for x in range(n)]# corresponds to above.\n",
    "    singleClusterHeight.extend([0]*(n-1))\n",
    "    clusterHeightList = singleClusterHeight\n",
    "\n",
    "    pairWiseDistMat = cdist(X, X, metric = \"euclidean\") + infDiag\n",
    "    currentClusters =  [set([x]) for x in range(n)]# single clusters\n",
    "    # this element is used for this function only and keeps track of the current clusters instead of all\n",
    "    # clusters at each iteration.\n",
    "\n",
    "    clusterIndx = 0 + n# +n to get beyond the initial single element clusters\n",
    "    for i in range(0 + n, n-1 + n):\n",
    "        # Your code here\n",
    "        ##STEP 2##\n",
    "        i_min,j_min = # get the index of the two closest observations i, j where i!= j\n",
    "        ##STEP 3##\n",
    "        height = \n",
    "        clusterSet = fuseClusters(i_min, j_min, currentClusters)\n",
    "        ##STEP 4##\n",
    "        # deleting rows and columns of distance mat corresponding to i_min and j_min clusters\n",
    "        assert clusterSet not in clusterSetList, \"about to add a set twice.\\n{}\".format(clusterSet)\n",
    "        currentClusters.append(clusterSet)\n",
    "        clusterSetList[clusterIndx] = clusterSet\n",
    "        clusterHeightList[clusterIndx] = height\n",
    "        # update pairwise distance matrix with the pairwise distance for the new cluster\n",
    "        newPairWiseDistance = calculateClusterDistances(X = X, clusterSetList = currentClusters, clusterIdx = -1)\n",
    "        pairWiseDistMat = \n",
    "        clusterIndx += 1\n",
    "    # End your code\n",
    "    clusterSanityCheck(clusterSetList, n)\n",
    "\n",
    "    assert len(clusterHeightList) == len(clusterSetList), \"each cluster needs a merge height\"\n",
    "    return(clusterSetList, clusterHeightList)\n",
    "\n",
    "\n",
    "clusterSetList, clusterHeightList = hclust(X_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterAssignments(clusterSetList, clusterHeightList, cutOffheight):\n",
    "    \"\"\"\n",
    "    Description: Determine cluster assignments  for each element using the clusters at created at\n",
    "        each iteration and a cutoff height.\n",
    "    Input: \n",
    "        clusterSetList (list(set())): A list of sets where each set contains the cluster merged at step i.\n",
    "            From this list you can create many clusters depending on your cut height.\n",
    "        clusterHeightList (list(float)): A list of floats. Each value is the height that each cluster was \n",
    "            merged at.\n",
    "        cutOffheight (int): Only consider clusters with a height below this value\n",
    "    Output:\n",
    "        maximalClusterSets (list(set)): This should the set of top level clusters which are under the height\n",
    "            cutoff.\n",
    "        clusterMapIdxs (list): Maps each observation to it's cluster. Cluster values are arbitrary, but starting\n",
    "        with the first maximal cluster as cluster number 1 isn't bad.\n",
    "    \"\"\"\n",
    "    maximalClusterSets = []\n",
    "    n = 0\n",
    "    # Your code here\n",
    "    for clusterSetCandidate, clusterHeight in zip(reversed(clusterSetList), reversed(clusterHeightList)):\n",
    "\n",
    "    # End your code\n",
    "    clusterMapIdxs = [-1]*n\n",
    "    # Your code here\n",
    "\n",
    "    # End your code\n",
    "    return(maximalClusterSets, clusterMapIdxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the number of clusters\n",
    "There are many ways to choose the number of clusters, but because we know there should be 10 clusters in our digit dataset we can vary the height cutoff to get as close to 10 as possible. The closer the better as this will help with checking your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximalClusterSets, clusterLabels = clusterAssignments(clusterSetList, clusterHeightList, cutOffheight = 0.0035)\n",
    "print(len(maximalClusterSets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code snagged from https://scikit-learn.org/stable/auto_examples/cluster/plot_digits_linkage.html\n",
    "def plot_clustering(X_red, labels, title=None):\n",
    "    x_min, x_max = np.min(X_red, axis=0), np.max(X_red, axis=0)\n",
    "    X_red = (X_red - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for i in range(X_red.shape[0]):\n",
    "        plt.text(X_red[i, 0], X_red[i, 1], str(y[i]),\n",
    "                 color=plt.cm.nipy_spectral(labels[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title, size=17)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_clustering(X_red, clusterLabels, \"Your own code for clustering\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from time import time\n",
    "clustering = AgglomerativeClustering(linkage = \"average\", n_clusters=10)\n",
    "t0 = time()\n",
    "clustering.fit(X_red)\n",
    "print(\"Average linkage run time :\\t%.2fs\" % (time() - t0))\n",
    "\n",
    "plot_clustering(X_red, clustering.labels_, \"Sklearn for clustering\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Computational Methods)",
   "language": "python",
   "name": "computational_methods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
