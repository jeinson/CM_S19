{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping and Permutation Tests\n",
    "In class we learned how to perform bootstrapping, and permutation tests. In today's lab we'll use both of these methods to 1) build a random forest almost from scratch, and assess how well singificantly different a machine learning model is from luck or random chance performance. After this lab you should have a deeper understanding of how both of these methods are implemented by libraries in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling in Data\n",
    "You can read more about the dataset [here](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "breastCancer = datasets.load_breast_cancer()\n",
    "X_all = breastCancer.data\n",
    "randomNumGen = np.random.RandomState(seed=23)\n",
    "E = randomNumGen.normal(size=X_all.shape, loc = 0.0, scale = 1)\n",
    "# Add noisy data to the informative features for make the task harder\n",
    "X_all += E\n",
    "y_all = breastCancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.25, random_state = 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Bootstrapping, Aggregation, and Random Forests\n",
    "In this section you'll implement a random forest model. Don't worry, you'll have ample access to scikit-learn libraries, but you won't be able to use the [RandomForestClassifer](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) because that would defeat the purpose of learning some of the ins and outs of this model.\n",
    "\n",
    "### Things to worry about\n",
    "1. What happens when you call fit on a model multiple times?\n",
    "2. Are you sampling with replacement during bootstrapping?\n",
    "3. Inevitable heat death of the universe\n",
    "4. What's for dinner?\n",
    "\n",
    "### Deliverables\n",
    "Fill in the ensemble model code below and using the comparison code below train it for 1,2,3,...,10 learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBootStrapData(X, y):\n",
    "    \"\"\"\n",
    "    Description: Implements the bootstrap using your own functions. Do not use any functionality\n",
    "        from sklearn.\n",
    "    Input:\n",
    "        X (numpy matrix): A numpy matrix of shape nxm\n",
    "        y (numpy array): A numpy array of length n\n",
    "    Output:\n",
    "        X_bs (numpy matrix): Same shape as X, with rows sampled with replacement from X\n",
    "        y_bs (numpy array): Similar to X_bs but based off of y\n",
    "    \"\"\"\n",
    "    bootStrapSampleIdxs = np.array(random.choices(np.arange(X.shape[0]), k = X.shape[0]))\n",
    "#         return(resample(X, y, replace = True, n_samples = X.shape[0]))\n",
    "    X_bs = X[bootStrapSampleIdxs]\n",
    "    y_bs = y[bootStrapSampleIdxs]\n",
    "    return(X_bs, y_bs)\n",
    "\n",
    "\n",
    "class ensembleClassifier(BaseEstimator, ClassifierMixin):  \n",
    "    \"\"\"\n",
    "    We're going to implement an ensemble classifier using a simple sklearn base estimator class.\n",
    "    There's a lot more to implementing an estimator in sklearn, but we'll only implement three methods\n",
    "    in addition to the init method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nEstimators):\n",
    "        \"\"\"\n",
    "        Description: Called when initializing the classifier. Don't do any heavy lifting here. Just store\n",
    "        information that your model will need when it's called. The init method should never learn the model,\n",
    "        that should be done in the fit method.\n",
    "        Note: It's s a good idea to name your objects with the same name as the arguments specified to\n",
    "        init the method.\n",
    "        Input:\n",
    "            nEstimators (int): The number of estimators to be fit for the enesmble method.\n",
    "        Output:\n",
    "            None\n",
    "        \"\"\"\n",
    "        # Store objects that you'll need for later.\n",
    "        # Your code here\n",
    "        self.nEstimators = nEstimators\n",
    "        # End your code\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Description: Fits the classifier by fitting all ensemble models on bootstrapped data.\n",
    "        You'll be making use of the generateBootStrapData() function. \n",
    "        All heavy lifting is done here. You'll need to store all estimators a list called estimators_.\n",
    "        self.estimators_ will contain nEstimators LogisticRegression() objects\n",
    "        Input:\n",
    "            X (numpy matrix): A numpy matrix of shape nxm\n",
    "            y (numpy array): A numpy array of length n\n",
    "        Output:\n",
    "            self (ensembleClassifier): Always return self when in the fit function to work with sklearn.\n",
    "        \"\"\"\n",
    "        # Fit nEstimators logistic regressions\n",
    "        # Your code here\n",
    "        self.estimators_ = [LogisticRegression(solver = \"liblinear\") for i in range(self.nEstimators)]\n",
    "\n",
    "        if self.nEstimators > 1:\n",
    "            for estimator in self.estimators_:\n",
    "                X_bootStrap, y_bootStrap = generateBootStrapData(X, y)\n",
    "                estimator.fit(X_bootStrap, y_bootStrap)\n",
    "        else:\n",
    "            self.estimators_[0].fit(X, y)\n",
    "        # End your code\n",
    "        return(self)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Description: For each of your classification models make a class prediction for each \n",
    "            observation. Take an average of all predictions and use a threshold of 0.5 to make a class prediction\n",
    "            to create an overall ensemble prediction.\n",
    "        Input:\n",
    "            X (numpy matrix): A numpy matrix of shape nxm. Can be unseen or seen data.\n",
    "        Output:\n",
    "            predictions (np.array): A numpy array of 1s or 0s indicating a prediction for all\n",
    "                n inputs in X.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            getattr(self, \"estimators_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You're gonna want to train the your estimators first my dude(et)\")\n",
    "        # Make some predictions\n",
    "        # Your code here\n",
    "        predictions = [estimator.predict(X) for estimator in self.estimators_]\n",
    "        predictions = np.array(predictions)\n",
    "        predictions = np.mean(predictions, axis = 0)\n",
    "        predictions[predictions >= 0.5] = 1\n",
    "        predictions[predictions < 0.5] = 0\n",
    "        # End your code\n",
    "        return(predictions)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Description: Using your prediction function predict the classes for X, and assess performance \n",
    "            against y using accuracy\n",
    "        Input:\n",
    "            X (numpy matrix): A numpy matrix of shape nxm. Can be unseen or seen data.\n",
    "            y (numpy array): A numpy array of classes with the same number of observations as X\n",
    "        Output:\n",
    "            accuracy (float): a float between 0 and 1 indicating how many elements you predicted the\n",
    "                correct class for\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        # Your code here\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        # end your code\n",
    "        return(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "clf_ens = ensembleClassifier(nEstimators = 2)#newton-cg', 'sag', 'saga' and 'lbfgs'\n",
    "clf_ens.fit(X = X_train, y = y_train)\n",
    "score = clf_ens.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testClassifier(X_train, y_train, X_test, y_test, nEstimators):\n",
    "    \"\"\"\n",
    "    Description: Runs your classifier a bunch of times to get an estimate of performance. Expects that\n",
    "        all methods have been completed in the ensembleClassifier class\n",
    "    Input:\n",
    "        X_train, y_train, X_test, y_test (numpy matrices and arrays): X_() is a matrix of observations\n",
    "            y_() is a numpy array of classes of the same shape as its X_() conterpart\n",
    "        nEstimators (int): Creates a new ensemble classifier each time with nEstimators classifiers.\n",
    "            NOTE: You might have to do something similar to this retrain multiple estimators. Notice how \n",
    "            I'm initializing a new object at each iteration. Think about (google) why I might be doing this.\n",
    "    Output\n",
    "        None: Just here to print.\n",
    "    \"\"\"\n",
    "    allScores = []\n",
    "    nRuns = 50\n",
    "    for i in range(nRuns):\n",
    "        clf_ens = ensembleClassifier(nEstimators = nEstimators)#newton-cg', 'sag', 'saga' and 'lbfgs'\n",
    "        clf_ens.fit(X = X_train, y = y_train)\n",
    "        score = clf_ens.score(X_test, y_test)\n",
    "        allScores.append(score)\n",
    "    mean = np.mean(allScores)\n",
    "    std = np.std(allScores)\n",
    "    print(\"Average score for {} runs and {} estimators: {} (std:{})\".format(nRuns, nEstimators, mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for 50 runs and 1 estimators: 0.9370629370629371 (std:0.0)\n",
      "Average score for 50 runs and 2 estimators: 0.9317482517482518 (std:0.010883958857814657)\n",
      "Average score for 50 runs and 3 estimators: 0.9299300699300699 (std:0.010511864293210382)\n",
      "Average score for 50 runs and 4 estimators: 0.9373426573426576 (std:0.011185314138815215)\n",
      "Average score for 50 runs and 5 estimators: 0.9331468531468532 (std:0.010003666988670017)\n",
      "Average score for 50 runs and 6 estimators: 0.9370629370629372 (std:0.00803435335180142)\n",
      "Average score for 50 runs and 7 estimators: 0.9325874125874126 (std:0.008005084207694631)\n",
      "Average score for 50 runs and 8 estimators: 0.9377622377622379 (std:0.007300913642594781)\n",
      "Average score for 50 runs and 9 estimators: 0.9348251748251748 (std:0.007054277042192154)\n",
      "Average score for 50 runs and 10 estimators: 0.938881118881119 (std:0.00882449877166285)\n"
     ]
    }
   ],
   "source": [
    "# Test the performance of your model by getting the measure of multiple runs.\n",
    "for i in np.arange(1, 11, 1):\n",
    "    testClassifier(X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, nEstimators = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Permutation Tests\n",
    "No we want to test if a classifier of our choice is better than a simple majority classifier, and assess how sure we are of this claim. We're going to use this by using even more bootstrapping to create new trainig datasets, train our classifier, and assess performance on the same test set. **You can use any classification model you want as long as it's accessible from sklearn, otherwise you're gonna have a bad time. You can even use your ensemble model.**\n",
    "\n",
    "In order to do this we're going to use our bootstrap model above to assess performance on even more bootstrap data. The general algorthm is as follows.\n",
    "\n",
    "Given $X_{train}$, $y_{train}$, $X_{test}$ and $y_{test}$ as inputs do.\n",
    "1. Sample $X^{bs}_{train}$ from $X_{train}$ and $y^{bs}_{train}$, from $y_{train}$ using the bootstrap algorithm.\n",
    "2. Train our model using $X^{bs}_{train}$\n",
    "3. Evaluate the ensemble model on $X_{test}$ and $y_{test}$\n",
    "4. Store our test statistic (accuracy)\n",
    "\n",
    "\n",
    "Next evaluate whether or not a majority classifier trained on $X_{train}$ and evaluated on $X_{test}$ has performance within the 95% confidence intervals of the ensemble model. Note: A majority classifier simple takes the majority class in the training set and assigns the class to all values it's evaluated on\n",
    "\n",
    "\n",
    "### Deliverables\n",
    "Plot a histogram of the ensemble model's **bootstrap performances** with vertical lines for the **lower and upper confidence intervals** as well as for the **majority classifer performance**. You can get all but the majority classifier values from the function `calculateConfidenceIntervals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateConfidenceIntervals(X_train, y_train, X_test, y_test, R, nEstimators, confInterval = 0.95):\n",
    "    \"\"\"\n",
    "    Description: Calculates confidence intervals of your model by obtaining R bootstrap samples of the \n",
    "        orginal training data, fitting a classifier on this data, and assessing performance on the original\n",
    "        testing data. Then the (1-confInterval)/2% of scores are trimmed from either side of the sorted\n",
    "        scores to assess which scores are within the confidence interval. Please refer to your reading\n",
    "        on confidence intervals in Practical Statistics for Data Scientists. \n",
    "    Input:\n",
    "        X_train, y_train, X_test, y_test (numpy matrices and arrays): X_() is a matrix of observations\n",
    "            y_() is a numpy array of classes of the same shape as its X_() conterpart\n",
    "        R (int): The number of times to generate bootstrap samples and train a model  \n",
    "        confInterval (float): A float between 0.0 and 1.0 indicating the confidence interval.\n",
    "    Output:\n",
    "        allScores (np.array): An array of scores generated using bootstrapped data.\n",
    "        lowerConfBound (float): An elemnt from allScores which indicates the cutoof for the upper bound\n",
    "            of the confidence interval\n",
    "        upperConfBound (float): An elemnt from allScores which indicates the cutoof for the lower bound\n",
    "            of the confidence interval\n",
    "    \"\"\"\n",
    "    allScores = [0.0]*R\n",
    "    # Your code here\n",
    "    for r in tqdm_notebook(range(R)):\n",
    "        clf = LogisticRegression(solver = \"liblinear\")\n",
    "        X_bs_train, y_bs_train = generateBootStrapData(X = X_train, y = y_train)\n",
    "        clf.fit(X = X_bs_train, y = y_bs_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        allScores[r] = score\n",
    "    allScores = np.sort(allScores)\n",
    "    nTrim = int(np.ceil(((1 - confInterval)/2)*R))\n",
    "    print(\"Trimming off {} elements from either side of scores\".format(nTrim))\n",
    "    lowerConfBound = allScores[(nTrim - 1)]\n",
    "    upperConfBound = allScores[-nTrim]\n",
    "    # End your code\n",
    "    return(allScores, lowerConfBound, upperConfBound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a603122b7ff64498874548daca579a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trimming off 26 elements from either side of scores\n"
     ]
    }
   ],
   "source": [
    "allScores, lowerConfBound, upperConfBound = calculateConfidenceIntervals(X_train = X_train, y_train = y_train,\n",
    "                                                                         X_test = X_test, y_test = y_test, R = 1000,\n",
    "                                                                         confInterval = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority classifier performance = 0.6643356643356644\n"
     ]
    }
   ],
   "source": [
    "# Implement code to \"train\" a majority classifier and get its accuracy on the test set.\n",
    "# Your code here\n",
    "if np.mean(y_train) >= 0.5:\n",
    "    majorityClass = 1\n",
    "else:\n",
    "    majorityClass = 0\n",
    "majorityClassiferPerf = np.mean(y_test == majorityClass)\n",
    "# End your code\n",
    "print(\"majority classifier performance = {}\".format(majorityClassiferPerf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot what is described in the deliverables\n",
    "# Your code here\n",
    "plt.hist(allScores, bins = 20, label='Permutation scores',\n",
    "         edgecolor='black')\n",
    "ylim = plt.ylim()\n",
    "xlim = plt.xlim()\n",
    "if xlim[0] > majorityClassiferPerf:\n",
    "    xlim = (majorityClassiferPerf - 0.025, xlim[1])\n",
    "plt.vlines(lowerConfBound, ymin = ylim[0], ymax = ylim[1], linestyle='--',\n",
    "         color='g', linewidth=3,\n",
    "         label = \"lower confidence bound\")\n",
    "plt.vlines(upperConfBound, ymin = ylim[0], ymax = ylim[1], linestyle='--',\n",
    "         color='g', linewidth=3,\n",
    "         label = \"upper confidence bound\")\n",
    "plt.vlines(majorityClassiferPerf, ymin = ylim[0], ymax = ylim[1], linestyle='--',\n",
    "         color='b', linewidth=3,\n",
    "         label = \"majority classifier\")\n",
    "plt.ylim(ylim)\n",
    "plt.xlim(xlim)\n",
    "plt.legend()\n",
    "plt.xlabel('Score')\n",
    "plt.show()\n",
    "# End your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Computational Methods)",
   "language": "python",
   "name": "computational_methods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
