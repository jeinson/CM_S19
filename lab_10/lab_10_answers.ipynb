{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 10: Word Embeddings\n",
    "Thinking of using stuff from here\n",
    "https://gist.github.com/mbednarski/da08eb297304f7a66a3840e857e060a0\n",
    "\n",
    "conda install -c conda-forge tqdm\n",
    "\n",
    "conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Janitorial Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCorpus = [\"First of all, quit grinnin’ like an idiot. Indians ain’t supposed to smile like that. Get stoic.\",\n",
    "             \"No. Like this. You gotta look mean, or people won’t respect you.\",\n",
    "              \" people will run all over you if you don’t look mean.\",\n",
    "              \"You gotta look like a warrior. You gotta look like you just came back from killing a buffalo.\",\n",
    "             \"But our tribe never hunted buffalo. We were fishermen.\"\n",
    "             \"What? You wanna look like you just came back from catching a fish?\",\n",
    "             \"This ain’t dances with salmon, you know. Thomas, you gotta look like a warrior.\"]\n",
    "maxDocs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/oliver/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 pub med abstracts\n"
     ]
    }
   ],
   "source": [
    "# Read in pubmed corpus into a text file\n",
    "\n",
    "import glob\n",
    "pubMedDataFolderPath = \"data/pubMed_corpus/\"\n",
    "pubMedDataFiles = glob.glob(pubMedDataFolderPath + \"*.txt\")\n",
    "pubMedCorpus = [\"\"]*len(pubMedDataFiles)\n",
    "for idx, pubMedDataPath in enumerate(pubMedDataFiles):\n",
    "    with open(pubMedDataPath, \"r\") as pubMedFile:\n",
    "        text = pubMedFile.read().strip()\n",
    "        pubMedCorpus[idx] = text\n",
    "pubMedCorpus = pubMedCorpus[0:maxDocs]\n",
    "print(\"{} pub med abstracts\".format(len(pubMedCorpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 ap articles\n"
     ]
    }
   ],
   "source": [
    "# Read in the ap corpus\n",
    "apTextFile = \"data/ap.txt\"\n",
    "apCorpus = []\n",
    "readText = False\n",
    "with open(apTextFile) as apDataFile:\n",
    "    for line in apDataFile:\n",
    "        if readText:\n",
    "            apCorpus.append(line.strip())\n",
    "            readText = False\n",
    "        if line == \"<TEXT>\\n\":\n",
    "            readText = True\n",
    "apCorpus = apCorpus[0:maxDocs]\n",
    "print(\"{} ap articles\".format(len(apCorpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/oliver/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "def removePunctuation(myStr):\n",
    "    excludedCharacters = string.punctuation + \"’\"\n",
    "    newStr = \"\".join(char for char in myStr if char not in excludedCharacters)\n",
    "    return(newStr)\n",
    "def removeStopWords(tokenList):\n",
    "    newTokenList = [tok for tok in tokenList if tok not in stopwords.words('english')]\n",
    "    return(newTokenList)\n",
    "def tokenize_corpus(corpus):\n",
    "    tokens = [removeStopWords(removePunctuation(x).lower().split()) for x in corpus]\n",
    "    return tokens\n",
    "\n",
    "apCorpusTokenized = tokenize_corpus(apCorpus)\n",
    "pubMedCorpusTokenized = tokenize_corpus(pubMedCorpus)\n",
    "testCorpusTokenized = tokenize_corpus(testCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ap corpus vocabulary\n",
      "Vocab size: 12864\n",
      "ap data tokenized in 0.04893183708190918 seconds\n",
      "\n",
      "Building pubMed corpus vocabulary\n",
      "Vocab size: 6888\n",
      "pubmed data tokenized in 0.02375960350036621 seconds\n",
      "\n",
      "Building test corpus vocabulary\n",
      "Vocab size: 36\n",
      "test data tokenized in 0.0003077983856201172 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from collections import Counter\n",
    "\n",
    "maxVocabSize = None\n",
    "\n",
    "def extractVocabMappers(tokenizedCorpus, vocabSizeMax = None):\n",
    "    UNK = \"<UNK>\"\n",
    "    flattenedCorpus = [item for sublist in tokenizedCorpus for item in sublist]\n",
    "    wordCounts = Counter(flattenedCorpus)\n",
    "    wordCounts = wordCounts.most_common(vocabSizeMax)\n",
    "    vocabulary = [word for word, count in wordCounts]\n",
    "    \n",
    "    # below is more readable but significantly slower code\n",
    "    if False:\n",
    "        vocabulary = []\n",
    "        for sentence in tqdm(tokenizedCorpus):\n",
    "            for token in sentence:\n",
    "                if token not in vocabulary:\n",
    "                    vocabulary.append(token)\n",
    "    vocabulary.append(UNK)\n",
    "    print(\"Vocab size: {}\".format(len(vocabulary)))\n",
    "    word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
    "    idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
    "    newTokenizedCorpus = []# all words missing from vocab replaced with <UNK>\n",
    "    for doc in tokenizedCorpus:\n",
    "        newDoc = [word if word in word2idx else UNK for word in doc]\n",
    "        newTokenizedCorpus.append(newDoc)\n",
    "    return(word2idx, idx2word, wordCounts, newTokenizedCorpus)\n",
    "\n",
    "start = time.time()\n",
    "print(\"Building ap corpus vocabulary\")\n",
    "word2Idx_ap, idx2Word_ap, vocabCount_ap, finalTokenizedCorpus_ap = extractVocabMappers(apCorpusTokenized,\n",
    "                                                                                       vocabSizeMax = maxVocabSize)\n",
    "print(\"ap data tokenized in {} seconds\\n\".format(time.time() - start))\n",
    "start = time.time()\n",
    "print(\"Building pubMed corpus vocabulary\")\n",
    "word2Idx_pubMed, idx2Word_pubMed, vocabCount_pubMed, finalTokenizedCorpus_pubMed = extractVocabMappers(pubMedCorpusTokenized,\n",
    "                                                                                                       vocabSizeMax = maxVocabSize)\n",
    "print(\"pubmed data tokenized in {} seconds\\n\".format(time.time() - start))\n",
    "start = time.time()\n",
    "print(\"Building test corpus vocabulary\")\n",
    "word2Idx_test, idx2Word_test, vocabCount_test, finalTokenizedCorpus_test = extractVocabMappers(testCorpusTokenized,\n",
    "                                                                                               vocabSizeMax = maxVocabSize)\n",
    "print(\"test data tokenized in {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateObservations(tokenizedCorpus, word2Idx):\n",
    "    window_size = 5\n",
    "    idxPairs = []\n",
    "    # for each sentence\n",
    "    for sentence in tokenizedCorpus:\n",
    "#         indices = [word2Idx[word] for word in sentence]\n",
    "        # for each word, threated as center word\n",
    "        for center_word_pos in range(len(sentence)):\n",
    "            # for each window position\n",
    "            for w in range(-window_size, window_size + 1):\n",
    "                context_word_pos = center_word_pos + w\n",
    "                # make soure not jump out sentence\n",
    "                if context_word_pos < 0 or context_word_pos >= len(sentence) or center_word_pos == context_word_pos:\n",
    "                    continue\n",
    "                idxPairs.append((sentence[center_word_pos], sentence[context_word_pos]))\n",
    "\n",
    "    idxPairs = np.array(idxPairs) # it will be useful to have this as numpy array\n",
    "    return(idxPairs)\n",
    "\n",
    "\n",
    "def generateWordSamplingProb(vocabCount, word2Idx):\n",
    "    wordSampleProbs = [0.0]*len(vocabCount)\n",
    "    numWords = np.sum([count**0.75 for word, count in vocabCount])\n",
    "    for idx in range(len(vocabCount)):\n",
    "        w,c = vocabCount[idx]\n",
    "        wordSampleProbs[word2Idx[w]] = (c**0.75)/(numWords)\n",
    "        \n",
    "        \n",
    "        \n",
    "    wordSampleProbs = []\n",
    "    numWords = np.sum([count for word, count in vocabCount])\n",
    "    for w,c in vocabCount:\n",
    "#         w,c = vocabCount[idx]\n",
    "        wordSampleProbs.extend([word2Idx[w]] * int(((c/numWords)**0.75)/0.001))\n",
    "    return(wordSampleProbs)\n",
    "    \n",
    "class SkipGram(nn.Module):\n",
    "    def __init__(self, vocabSize, embedSize, vocabCount, word2Idx):\n",
    "        super(SkipGram, self).__init__()\n",
    "        self.vocabSize = vocabSize\n",
    "        self.word2Idx = word2Idx\n",
    "#         self.centerEmbeddings = nn.Embedding(vocab_size, embd_size)\n",
    "#         self.contextEmbeddings = nn.Embedding(vocab_size, embd_size)\n",
    "#         self.embeddings = nn.Embedding(vocab_size, embd_size)\n",
    "        \n",
    "        self.centerEmbeddings = nn.Parameter(torch.randn(vocabSize,\n",
    "                                                     embedSize).float(), requires_grad=True)\n",
    "        self.contextEmbeddings = nn.Parameter(torch.randn(vocabSize,\n",
    "                                                      embedSize).float(), requires_grad=True)\n",
    "        self.wordSampleProbs = generateWordSamplingProb(vocabCount, word2Idx)\n",
    "        self.logSigmoid = nn.LogSigmoid()\n",
    "#         self.paramList = nn.ModuleList([self.centerEmbeddings, self.contextEmbeddings] )\n",
    "    def getNegSample(self, k, centerWord):\n",
    "        vocabSizeWithoutUnk = self.vocabSize - 1\n",
    "#         negSample = np.random.choice(vocabSizeWithoutUnk,\n",
    "#                                      size = k, replace = True, p = self.wordSampleProbs)\n",
    "        negSample = random.sample(self.wordSampleProbs, k)\n",
    "        while self.word2Idx[centerWord] in negSample:\n",
    "#             negSample = np.random.choice(vocabSizeWithoutUnk,\n",
    "#                                          size = k, replace = True, p = self.wordSampleProbs)\n",
    "            negSample = random.sample(self.wordSampleProbs, k)\n",
    "        return(negSample)\n",
    "    def forward(self, center, context, negSampleIndices = None):\n",
    "#         focus = torch.autograd.Variable(torch.LongTensor([0]))\n",
    "#         context = torch.autograd.Variable(torch.LongTensor([0]))\n",
    "#         allEmbeddingIdxs = torch.autograd.Variable(torch.LongTensor([np.arange(0,self.vocabSize)]))\n",
    "\n",
    "\n",
    "#         embedCenter = self.centerEmbeddings(center).view((1, -1))\n",
    "#         embedContext = self.contextEmbeddings(context).view((1, -1))\n",
    "# #         print(allEmbeddingIdxs)\n",
    "#         allContextEmbeddings = self.contextEmbeddings(allEmbeddingIdxs).squeeze()\n",
    "#         num = torch.exp(torch.mm(embedContext, torch.t(embedCenter)))\n",
    "#         denom = torch.exp(torch.mm(allContextEmbeddings, torch.t(embedCenter))).sum()\n",
    "#         logProb = torch.log(num/denom)\n",
    "        embedCenter = self.centerEmbeddings[center].view((1, -1))\n",
    "        embedContext = self.contextEmbeddings[context].view((1, -1))       \n",
    "        if negSampleIndices is not None:\n",
    "#             print(\"hey\")\n",
    "            posVal = self.logSigmoid (torch.mm(embedContext, torch.t(embedCenter)))\n",
    "#             start = time.time()\n",
    "#             for i in range(1000):\n",
    "            negVal = torch.mm(self.contextEmbeddings[negSampleIndices], torch.t(embedCenter))\n",
    "            negVal = self.logSigmoid (-torch.sum(negVal))\n",
    "#             print(\"avg time: {}\".format((time.time() - start)/100))\n",
    "#             print(torch.mm(self.contextEmbeddings[negSampleIndices], torch.t(embedCenter)).shape)\n",
    "#             1/0\n",
    "            logProb = posVal + negVal\n",
    "        else:\n",
    "#             allEmbeddingIdxs = torch.autograd.Variable(torch.LongTensor([np.arange(0,self.vocabSize)]))\n",
    "\n",
    "\n",
    "\n",
    "    #         print(allEmbeddingIdxs)\n",
    "    #         allContextEmbeddings = self.contextEmbeddings(allEmbeddingIdxs).squeeze()\n",
    "            num = torch.exp(torch.mm(embedContext, torch.t(embedCenter)))\n",
    "#             start = time.time()\n",
    "#             for i in range(1000):\n",
    "            denom = torch.exp(torch.mm(self.contextEmbeddings, torch.t(embedCenter))).sum()\n",
    "#             print(\"avg time: {}\".format((time.time() - start)/100))\n",
    "#             print(torch.exp(torch.mm(self.contextEmbeddings, torch.t(embedCenter))).shape)\n",
    "#             1/0\n",
    "            logProb = torch.log(num/denom)\n",
    "    \n",
    "        return(logProb)\n",
    "\n",
    "\n",
    "def train_skipgram(embeddingSize, trainingData, vocabCount, word2Idx, k):\n",
    "    print(\"training on {} observations\".format(len(trainingData)))\n",
    "    losses = []\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model = SkipGram(vocabSize = len(word2Idx), embedSize = embeddingSize,\n",
    "                     vocabCount = vocabCount, word2Idx = word2Idx)\n",
    "#     print(model)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(n_epoch), position = 0):\n",
    "#         print(\"entered epoch\")\n",
    "        total_loss = .0\n",
    "        for in_w, out_w in tqdm_notebook(trainingData, position = 1):\n",
    "            if k is not None:\n",
    "                negSamples = model.getNegSample(k = k, centerWord = in_w)\n",
    "            else:\n",
    "                negSamples = None\n",
    "#             print(\"neg samples found\")\n",
    "#             print(negSamples)\n",
    "            in_w_var = word2Idx[in_w]#torch.autograd.Variable(torch.LongTensor([word2Idx[in_w]]))\n",
    "            out_w_var = word2Idx[out_w]#torch.autograd.Variable(torch.LongTensor([word2Idx[out_w]]))\n",
    "#             if in_w in word2Idx:\n",
    "#                 in_w_var = word2Idx[in_w]#torch.autograd.Variable(torch.LongTensor([word2Idx[in_w]]))\n",
    "#             else:\n",
    "#                 in_w_var = word2Idx[\"<UNK>\"]\n",
    "#             if out_w in word2Idx:\n",
    "#                 out_w_var = word2Idx[out_w]#torch.autograd.Variable(torch.LongTensor([word2Idx[out_w]]))\n",
    "#             else:\n",
    "#                 out_w_var = word2Idx[\"<UNK>\"]\n",
    "            \n",
    "            model.zero_grad()\n",
    "            log_probs = model(in_w_var, out_w_var, negSampleIndices = negSamples)\n",
    "            loss = -log_probs[0]#loss_fn(log_probs[0], torch.autograd.Variable(torch.Tensor([1])))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.data.numpy()\n",
    "        losses.append(total_loss)\n",
    "        if epoch % 10 == 0 or n_epoch <= 10:    \n",
    "            print(f'Loss at epoch {epoch}: {total_loss/len(trainingData)}')\n",
    "    return(model, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 380 observations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7cf28938c642758823e0b5c1e32c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05704acb270649da93603a3723124a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: [5.711178]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d018e792d994667863020735d2e6247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2007a7518370488e895bba0065f806b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565024acc0f249d98e682451b42ca3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254ac14a73ee47ed94ea078662e1a1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08afb78fb9994914a9d862bb7502c4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b55ca351d4d4b328716f003b448f082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860076783de74628acd61ef57a603ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bd98ed83624fcdb38bd421f05e4482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6df7988ee064b49be0564a1c3c8940b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e1fddc335a4a89b1789799b7b0d468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 10: [4.792516]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8767f81c5cf84f799d423fb75644ff92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348b827e2d6b4edd992a052396d58fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a1d71c5e1941d2b976ac31a288775a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615bde30267f416388ef6b8193df0df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b2a25a1e0c4ff69f201f58d1e8017a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8bf5ef13824a688200982177e7a3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527a3c3a1ee3470aa8a8e1fcc79140ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e153e399574cc1a8104b54ed61f445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1470c3b11e9f47e1be3b54e82e8f54fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5484d8918fed4008ada8c844ae96c0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 20: [4.375297]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d32039a245443385d1591efb59acf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132e46647362408f91e1cab858b0fb51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae91236660094b198fbed7e14fbc97b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c47e4c58e14a53af243792e4cd1554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac02558362746f99bd6e1bc883790d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a2038dfcae4f18893d7fb5f73ee9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb81533544574dc8a8dc1d153167732e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c494cddb44c4f42896caf6c73ebabca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc7deaae5234a4791a3cc846ac6f3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e998a4bc5ee64581b401ae8de876f52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 30: [4.117554]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7aaca79613a4eaab7cd3a1bb4016f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e0b4ec298a4b9984b5141a4c7a59bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6a332d296c4d8eabf8d3c4c1890fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8aa59a072d94de6bd001815597bc578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbae8e57f43d43eca11bf70e0a1836a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bd5f1452ae481fb94f4c9ebba253f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b325ba748559434cab4df67fd9a7bbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6d68b628ff4ab1b29041da71c6ea01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cea3f2af045498baed0d27a1e76c264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc8c8d0722e43989c51d0cafc4c78ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 40: [3.9415078]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3007c693c1ab4cf5865ec99c2df71bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b628b6da99c424ca0aa20b87916728d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001fb12a25ec4cbe81fde00e8fa08808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c4687ee50a49d2a15aaa8c1363bc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df7074373924edf8dedada3576e3c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30e4c0bba2140b3abfb7f601df655a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2693d228e2134aada97768d601b27488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fcd86ccc814bf3997424290c484ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cfb30b1dd947839d9a1dfd9a7980b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b5a2ad41174ecaa22525b3f7d86fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 50: [3.8134084]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa66845560454d96be9a64e099c6fac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eef808bd7c444aa79d49a5c283921c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd38f79a90b497b86e058a3b5c03d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dbb73e932f4115b298f4d379ff304c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2037de0fcd0742a2a462fcd36b91b06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43ef18740014d0c9beae698ed774572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b0910eea57497facc5907d5488885c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a91463aec8d4aa388cd785aa918ec7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eb409dc628413c827daa037a8c5cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=380), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embd_size = 100\n",
    "learning_rate = 0.001\n",
    "n_epoch = 60\n",
    "idxPairsTest = generateObservations(tokenizedCorpus = finalTokenizedCorpus_test, word2Idx = word2Idx_test)\n",
    "sg_model, sg_losses = train_skipgram(embeddingSize = 5, trainingData = idxPairsTest, vocabCount = vocabCount_test,\n",
    "                                     word2Idx = word2Idx_test, k = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 587990 observations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ef8546213f42adb4d08e34b0852347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ab459953cd40eb83eaa4e55c506009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=587990), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: [24.51307335]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c8ef215a8d4d28918211e3125b11d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=587990), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: [21.3692954]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f46afe35df411499ebe47b2f2cacd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=587990), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 2: [19.56708107]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c172a7181aa4211ab0dd00ba9ba9ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=587990), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 3: [18.27246042]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4afaeb2c1c45b59f5a4855eeb0d1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=587990), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 4: [17.27497066]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2887d3af0b14ef9bcbd36ab93263c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=587990), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 5: [16.4724298]\n"
     ]
    }
   ],
   "source": [
    "embeddingSize = 50\n",
    "learning_rate = 0.001\n",
    "n_epoch = 6\n",
    "idxPairsAP = generateObservations(tokenizedCorpus = finalTokenizedCorpus_ap, word2Idx = word2Idx_ap)\n",
    "sg_model, sg_losses = train_skipgram(embeddingSize = embeddingSize, trainingData = idxPairsAP,\n",
    "                                     vocabCount = vocabCount_ap,\n",
    "                                     word2Idx = word2Idx_ap, k = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 238040 observations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d73d627d77f4bf7bc4b64bdda3b9548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1d144857b84653954ab92ce7d6d67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238040), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 0.001267857551574707\n",
      "torch.Size([7492, 1])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-144451550062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m sg_model, sg_losses = train_skipgram(embeddingSize = embeddingSize, trainingData = idxPairsAP,\n\u001b[1;32m      6\u001b[0m                                      \u001b[0mvocabCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabCount_ap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                      word2Idx = word2Idx_ap, k = None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-100-612c12afb831>\u001b[0m in \u001b[0;36mtrain_skipgram\u001b[0;34m(embeddingSize, trainingData, vocabCount, word2Idx, k)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_w_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_w_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegSampleIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnegSamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#loss_fn(log_probs[0], torch.autograd.Variable(torch.Tensor([1])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Computational_methods/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-100-612c12afb831>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, center, context, negSampleIndices)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avg time: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedCenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mlogProb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "embeddingSize = 20\n",
    "learning_rate = 0.001\n",
    "n_epoch = 1\n",
    "idxPairsAP = generateObservations(tokenizedCorpus = finalTokenizedCorpus_ap, word2Idx = word2Idx_ap)\n",
    "sg_model, sg_losses = train_skipgram(embeddingSize = embeddingSize, trainingData = idxPairsAP,\n",
    "                                     vocabCount = vocabCount_ap,\n",
    "                                     word2Idx = word2Idx_ap, k = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 238040 observations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935c2a35815e4ca38c9e15be944253eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a727a5aca3d4a49a1abb2422ee8b109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=238040), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: [18.14535792]\n"
     ]
    }
   ],
   "source": [
    "embeddingSize = 20\n",
    "learning_rate = 0.001\n",
    "n_epoch = 1\n",
    "idxPairsAP = generateObservations(tokenizedCorpus = finalTokenizedCorpus_ap, word2Idx = word2Idx_ap)\n",
    "sg_model, sg_losses = train_skipgram(embeddingSize = embeddingSize, trainingData = idxPairsAP,\n",
    "                                     vocabCount = vocabCount_ap,\n",
    "                                     word2Idx = word2Idx_ap, k = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 128126 observations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc62bff31ca4e77baf7a5bfb08278bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9154fef51de747e4adfe44cb5dac8f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: [-9.896313]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb8d73b601d43768de6918c821f4488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c008a277fc74137b2af7b6ffc485aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d101a1d0c0c4e14b413f7a1f4d4799b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a8a2b93d9e4b8aa0189de0642888af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddingSize = 20\n",
    "learning_rate = 0.001\n",
    "n_epoch = 5\n",
    "idxPairsPubMed = generateObservations(tokenizedCorpus = finalTokenizedCorpus_pubMed, word2Idx = word2Idx_pubMed)\n",
    "sg_model, sg_losses = train_skipgram(embeddingSize = embeddingSize, trainingData = idxPairsPubMed,\n",
    "                                     vocabCount = vocabCount_pubMed,\n",
    "                                     word2Idx = word2Idx_pubMed, k = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on 128126 observations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ce7c017a094b4caccda10ed03277cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f290ea26844224bd6feecf574b6a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0: [15.96258663]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d77256ddea04b808095f900c98658b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03937ccab254778876c78e4b13af5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5025528732cb48d29bf1e89b1b4ca40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109681250c2d43fd8906e6af918823ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=128126), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddingSize = 20\n",
    "learning_rate = 0.001\n",
    "n_epoch = 5\n",
    "idxPairsPubMed = generateObservations(tokenizedCorpus = finalTokenizedCorpus_pubMed, word2Idx = word2Idx_pubMed)\n",
    "sg_model, sg_losses = train_skipgram(embeddingSize = embeddingSize, trainingData = idxPairsPubMed,\n",
    "                                     vocabCount = vocabCount_pubMed,\n",
    "                                     word2Idx = word2Idx_pubMed, k = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2045222.4], dtype=float32),\n",
       " array([1862422.1], dtype=float32),\n",
       " array([1746688.], dtype=float32),\n",
       " array([1662227.6], dtype=float32),\n",
       " array([1596516.5], dtype=float32)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "def listNearestWords(model, idx2Word, referenceWords, topN):\n",
    "    assert len(idx2Word) == len(model.word2Idx), \"Possibly passed in two different vocabularies\"\n",
    "    embeddings = model.centerEmbeddings.data.numpy()\n",
    "    distMat = cdist(embeddings, embeddings, metric = \"cosine\")\n",
    "    for word in referenceWords:\n",
    "        wordIdx = model.word2Idx[word]\n",
    "#         print(np.argmin(distMat[wordIdx,:]))\n",
    "        closestIndices = np.argsort(distMat[wordIdx,:])[0:topN]\n",
    "        closestWords = [(idx2Word[idx], distMat[wordIdx, idx]) for idx in closestIndices]\n",
    "        for elem in closestWords:\n",
    "            print(elem)\n",
    "        print(\"*\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bush', 1.1102230246251565e-16)\n",
      "('president', 0.13244959422732927)\n",
      "('would', 0.13662114021683736)\n",
      "('people', 0.1433898401874425)\n",
      "('government', 0.18918568623643628)\n",
      "('also', 0.19677553426517247)\n",
      "('said', 0.20960274614864016)\n",
      "('us', 0.21823901837751392)\n",
      "('years', 0.22026618420593613)\n",
      "('could', 0.2219275275544691)\n",
      "**************************************************\n",
      "\n",
      "('soviet', 0.0)\n",
      "('union', 0.19148760713372004)\n",
      "('people', 0.24888523336252888)\n",
      "('officials', 0.2694699100602378)\n",
      "('bush', 0.27084279256233157)\n",
      "('government', 0.27761080050898956)\n",
      "('us', 0.2848540779235168)\n",
      "('could', 0.2928006077097679)\n",
      "('also', 0.303375641062432)\n",
      "('national', 0.3039809919761105)\n",
      "**************************************************\n",
      "\n",
      "('stock', 0.0)\n",
      "('figures', 0.4962425348903996)\n",
      "('firearms', 0.499091976045016)\n",
      "('capiz', 0.5366904780385411)\n",
      "('drugrelated', 0.5462987123293082)\n",
      "('calypso', 0.5514191343034507)\n",
      "('roses', 0.5667759478604235)\n",
      "('incorporated', 0.5673369273215838)\n",
      "('advanced', 0.5682758029526187)\n",
      "('nelson', 0.5689563278800276)\n",
      "**************************************************\n",
      "\n",
      "('dukakis', 0.0)\n",
      "('one', 0.44060955968356585)\n",
      "('say', 0.4636591701889008)\n",
      "('president', 0.48548051837734907)\n",
      "('bush', 0.49211743159626764)\n",
      "('would', 0.4977323853893594)\n",
      "('friday', 0.514673537814498)\n",
      "('tuesday', 0.520132838518949)\n",
      "('new', 0.523577655233828)\n",
      "('monday', 0.5243023488893535)\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listNearestWords(model = sg_model, idx2Word = idx2Word_ap,\n",
    "                 referenceWords = [\"bush\", \"soviet\", \"stock\", \"dukakis\"], topN = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organized', 'union', 'boost', 'behind', 'single', 'candidate', 'saturdays', 'democratic', 'caucuses', 'michigan', 'state', 'union', 'members', 'wield', 'clout', 'almost', 'anywhere', 'else', 'national', 'labor', 'leaders', 'assuming', 'michael', 'dukakis', 'eventual', 'nominee', 'prevented', 'endorsing', 'appears', 'growing', 'rankandfile', 'support', 'jesse', 'jackson', 'gotten', 'union', 'votes', 'candidates', 'primaries', 'far', 'richard', 'gephardt', 'also', 'considerable', 'union', 'support', 'none', 'democratic', 'candidates', 'appears', 'hearts', 'votes', 'majority', 'states', '750000', 'rankandfile', 'union', 'workers', 'nearly', 'half', 'members', 'united', 'auto', 'workers']\n",
      "['republican', 'nominee', 'george', 'bush', 'said', 'felt', 'nervous', 'voted', 'today', 'adopted', 'home', 'state', 'texas', 'ended', 'presidential', 'campaign', 'telling', 'voters', 'election', 'referendum', 'philosophy', 'way', 'life', 'vice', 'president', 'wife', 'barbara', 'voted', 'hotel', 'conference', 'room', 'set', 'polling', 'place', 'couple', 'visited', 'local', 'republican', 'headquarters', 'talk', 'people', 'working', 'get', 'vote', 'emerging', 'voting', 'booth', 'bush', 'asked', 'felt', 'nervous', 'everytime', 'vote', 'feel', 'nervous', 'said', 'asked', 'outcome', 'replied', 'predictions', 'gop', 'headquarters', 'bush', 'personally', 'made', 'halfdozen', 'telephone', 'calls', 'im', 'kidding', 'told', 'one', 'person', 'apparently', 'expressed', 'skepticism', 'bush', 'line', 'done', 'hard', 'work', 'key', 'get', 'vote', 'said', 'vice', 'president', 'also', 'showed', 'french', 'reporter', 'france', 'je', 'peux', 'parler', 'un', 'peu', 'de', 'francais', 'said', 'explaining', 'could', 'speak', 'language', 'little', 'added', 'felt', 'tres', 'heureux', 'aujourdhui', 'happy', 'today', 'bush', 'told', 'reporters', 'glad', 'campaign', 'planned', 'relaxed', 'family', 'day', 'lot', 'exercise', 'planned', 'watch', 'election', 'returns', 'television', 'family', 'members', 'friends', 'home', 'houston', 'condominiumhotel', 'complex', 'bush', 'wrapped', 'campaign', 'monday', 'final', 'swing', 'michigan', 'ohio', 'missouri', 'attended', 'raucus', 'rally', 'monday', 'evening', 'galleria', 'shopping', 'mall', 'country', 'stars', 'loretta', 'lynn', 'crystal', 'gayle', 'mo', 'bandy', 'entertained', 'several', 'thousand', 'fans', 'todays', 'election', 'referendum', 'peace', 'prosperity', 'bush', 'told', 'crowd', 'referendum', 'philosophy', 'way', 'life', 'thats', 'well', 'alive', 'right', 'deep', 'heart', 'texas', 'said', 'halfhour', 'paid', 'tv', 'advertisment', 'monday', 'night', 'republican', 'presidential', 'nominee', 'summed', 'themes', 'campaign', 'said', 'rival', 'michael', 'dukakis', 'experience', 'national', 'security', 'affairs', 'dont', 'believe', 'take', 'risk', 'issue', 'important', 'national', 'security', 'said', 'ad', 'broadcast', 'three', 'major', 'networks', 'right', 'dukakis', 'aired', 'halfhour', 'spot', 'later', 'softspeaking', 'bush', 'talked', 'viewers', 'minutes', 'end', 'halfhour', 'commercial', 'featured', 'biographical', 'campaign', 'scenes', 'set', 'music', 'narration', 'well', 'endorsement', 'president', 'reagan', 'various', 'bush', 'family', 'members', 'respect', 'opponent', 'admire', 'devotion', 'family', 'appreciate', 'decision', 'enter', 'public', 'service', 'bush', 'said', 'believe', 'guided', 'fundamentally', 'different', 'philosophies', 'great', 'divide', 'honest', 'difference', 'opinion', 'approach', 'lead', 'america', '90s', 'stronger', 'secure', 'ever', 'bush', 'also', 'echoed', 'president', 'reagans', '1980', 'campaign', 'line', 'saying', 'elect', 'president', 'better', 'four', 'years', 'today', 'ad', 'made', 'mention', 'bushs', 'running', 'mate', 'sen', 'dan', 'quayle', 'indiana', 'whose', 'qualifications', 'issue', 'campaign', 'bush', 'appeared', 'jovial', 'mood', 'monday', 'nationwide', 'polls', 'showed', 'holding', 'lead', 'dukakis', 'accompanied', 'top', 'campaign', 'advisers', 'bush', 'spent', 'final', 'campaign', 'day', 'addressing', 'rallies', 'suburb', 'detroit', 'rural', 'ashland', 'ohio', 'st', 'louis', 'calling', 'voters', 'reject', 'failed', 'liberal', 'policies', 'past', 'bush', 'also', 'seemed', 'reflective', 'mood', 'talked', 'campaign', 'meant', 'sees', 'ahead', 'sometimes', 'theres', 'ups', 'said', 'sometimes', 'theres', 'downs', 'sometimes', 'get', 'written', 'great', 'experts', 'sometimes', 'bounce', 'back', 'ill', 'tell', 'get', 'strength', 'get', 'strength', 'travelling', 'around', 'united', 'states', 'america', 'meeting', 'visiting', 'listening', 'heartbeat', 'comes', 'american', 'people', 'bush', 'said', 'confident', 'negativism', 'campaign', 'would', 'soon', 'behind', 'trust', 'good', 'judgment', 'american', 'people', 'immediately', 'shift', 'gears', 'start', 'looking', 'future', 'said', 'interview', 'radio', 'reporters']\n",
      "['michael', 'dukakis', 'getting', 'early', 'morning', 'exercise', 'walking', 'pittsburgh', 'street', 'someone', 'gave', 'cry', 'recognition', 'hey', 'isnt', 'caliguiri', 'wasnt', 'pittsburgh', 'mayor', 'richard', 'caliguiri', 'frontrunner', 'democratic', 'presidential', 'nomination', 'guess', 'mayor', 'look', 'alike', 'dukakis', 'said', 'described', 'sunday', 'morning', 'greeting', 'theres', 'old', 'saying', 'italian', 'one', 'face', 'one', 'race', 'part', 'family', 'far', 'ahead', 'polls', 'tuesdays', 'primary', 'dukakis', 'said', 'incident', 'shows', 'need', 'lot', 'work', 'make', 'sure', 'people', 'know', 'dukakis', 'ballot', 'massachusetts', 'governor', 'working', 'hard', 'taking', 'whistlestop', 'train', 'tour', 'across', 'western', 'pennsylvania', 'sunday', 'making', 'sixcity', 'flying', 'tour', 'state', 'today', 'dukakis', 'looking', 'fourth', 'straight', 'bigstate', 'win', 'surviving', 'competitor', 'jesse', 'jackson', 'tighten', 'grip', 'frontrunners', 'crown', 'widen', 'margin', 'delegate', 'count', 'win', 'big', 'tuesday', 'give', 'us', 'tremendous', 'boost', 'dukakis', 'told', 'big', 'crowd', 'students', 'pennsylvania', 'state', 'university', 'campus', 'welcoming', 'back', 'wife', 'kitty', 'penn', 'state', 'graduate', 'cold', 'cloudy', 'day', 'pittsburgh', 'greensburg', 'johnstown', 'altoona', 'dukakis', 'hit', 'message', 'good', 'jobs', 'economic', 'development', 'region', 'devastated', 'changes', 'steel', 'coal', 'industries', 'cant', 'bring', 'good', 'jobs', 'economic', 'opportunity', 'back', 'johnstowns', 'country', 'something', 'matter', 'us', 'told', 'crowd', 'believe', 'believe', 'going', 'dukakis', 'drew', 'parallels', 'new', 'englands', 'economic', 'troubles', 'past', 'pennsylvanias', 'troubles', 'present', 'new', 'englander', 'went', 'kind', 'pain', 'economic', 'distress', 'said', 'greensburg', 'communities', 'come', 'back', 'communities', 'going', 'come', 'back', 'drawing', 'two', 'weekend', 'debates', 'democrats', 'dukakis', 'talked', 'jackson', 'agree', 'many', 'issues', 'instead', 'investing', 'lot', 'exotic', 'weapon', 'systems', 'marginal', 'value', 'weve', 'got', 'take', 'resources', 'put', 'rev', 'jackson', 'said', 'saturday', 'infrastructure', 'sunday', 'dukakis', 'brushed', 'suggestions', 'jackson', 'put', 'budget', 'cant', 'prepare', 'budget', 'next', 'year', 'thats', 'absurd', 'told', 'reporters', 'chartered', 'amtrak', 'train', 'nicknamed', 'pennsylvania', 'presidential', 'unlimited', 'dukakis', 'resisted', 'pressure', 'new', 'jackson', 'tactic', 'urging', 'massive', 'new', 'spending', 'education', 'drug', 'control', 'efforts', 'programs', 'frontrunner', 'went', 'list', 'education', 'programs', 'says', 'involve', 'modest', 'spending', 'increases', 'jackson', 'said', 'federal', 'government', 'double', 'spending', 'education', 'going', 'run', 'nations', 'school', 'system', 'washington', 'dukakis', 'said', 'thing', 'president', 'set', 'priorities', 'get', 'democratic', 'candidate', 'also', 'took', 'couple', 'swipes', 'george', 'bush', 'saying', 'republican', 'nomineetobe', 'seems', 'interested', 'building', 'aircraft', 'carriers', 'rebuilding', 'nations', 'railroads', 'highways', 'mr', 'bush', 'critical', 'oppose', 'spending', '36', 'billion', 'two', 'supercarrier', 'task', 'forces', 'dont', 'need', 'cant', 'afford', 'dukakis', 'said', 'thinks', 'thats', 'ought', 'put', 'scarce', 'resources', 'going', 'fundamental', 'issue', 'campaign', 'think', 'know', 'american', 'people', 'tired', 'crumbling', 'bridges', 'congested', 'airports', 'jammed', 'highways', 'homeless', 'people', 'streets', 'doorways', 'want', 'change', 'dukakis', 'democratic', 'nominee', 'perhaps', 'get', 'wish', 'expressed', 'wistfully', 'pittsburgh', 'know', 'suppose', 'wed', 'like', 'suppose', 'im', 'household', 'word', 'told', 'small', 'crowd', 'id', 'like', 'one', 'days', 'come', 'pittsburgh', 'hear', 'hey', 'isnt', 'dukakis']\n"
     ]
    }
   ],
   "source": [
    "for elem in finalTokenizedCorpus_ap:\n",
    "    if \"dukakis\" in elem:\n",
    "        print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cancer\" in sg_model.word2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'said': 0,\n",
       " 'percent': 1,\n",
       " 'year': 2,\n",
       " 'new': 3,\n",
       " 'us': 4,\n",
       " 'years': 5,\n",
       " 'people': 6,\n",
       " 'one': 7,\n",
       " 'would': 8,\n",
       " 'two': 9,\n",
       " 'also': 10,\n",
       " 'soviet': 11,\n",
       " 'president': 12,\n",
       " 'police': 13,\n",
       " 'last': 14,\n",
       " 'oil': 15,\n",
       " 'government': 16,\n",
       " 'bank': 17,\n",
       " 'officials': 18,\n",
       " 'could': 19,\n",
       " 'ago': 20,\n",
       " 'first': 21,\n",
       " 'national': 22,\n",
       " 'state': 23,\n",
       " 'million': 24,\n",
       " 'states': 25,\n",
       " 'prices': 26,\n",
       " 'three': 27,\n",
       " 'official': 28,\n",
       " 'reported': 29,\n",
       " 'back': 30,\n",
       " 'monday': 31,\n",
       " 'dukakis': 32,\n",
       " 'rose': 33,\n",
       " 'rate': 34,\n",
       " 'bush': 35,\n",
       " 'fire': 36,\n",
       " 'war': 37,\n",
       " 'get': 38,\n",
       " 'military': 39,\n",
       " 'economic': 40,\n",
       " 'thursday': 41,\n",
       " 'company': 42,\n",
       " 'time': 43,\n",
       " 'made': 44,\n",
       " 'saying': 45,\n",
       " 'today': 46,\n",
       " 'american': 47,\n",
       " 'since': 48,\n",
       " 'roberts': 49,\n",
       " 'dont': 50,\n",
       " 'federal': 51,\n",
       " 'told': 52,\n",
       " 'mrs': 53,\n",
       " 'noriega': 54,\n",
       " 'forces': 55,\n",
       " 'months': 56,\n",
       " 'may': 57,\n",
       " 'rating': 58,\n",
       " 'good': 59,\n",
       " 'friday': 60,\n",
       " 'long': 61,\n",
       " 'day': 62,\n",
       " 'top': 63,\n",
       " 'united': 64,\n",
       " 'saudi': 65,\n",
       " 'use': 66,\n",
       " 'economy': 67,\n",
       " 'campaign': 68,\n",
       " 'gorbachev': 69,\n",
       " 'killed': 70,\n",
       " 'officers': 71,\n",
       " 'billion': 72,\n",
       " 'take': 73,\n",
       " 'jackson': 74,\n",
       " 'program': 75,\n",
       " 'washington': 76,\n",
       " 'end': 77,\n",
       " 'union': 78,\n",
       " 'gas': 79,\n",
       " 'gorbachevs': 80,\n",
       " 'see': 81,\n",
       " 'went': 82,\n",
       " '10': 83,\n",
       " 'foreign': 84,\n",
       " 'peres': 85,\n",
       " 'iraq': 86,\n",
       " 'report': 87,\n",
       " 'news': 88,\n",
       " 'many': 89,\n",
       " 'waste': 90,\n",
       " 'died': 91,\n",
       " 'believe': 92,\n",
       " 'man': 93,\n",
       " 'september': 94,\n",
       " 'part': 95,\n",
       " 'home': 96,\n",
       " 'city': 97,\n",
       " '1987': 98,\n",
       " 'tuesday': 99,\n",
       " 'five': 100,\n",
       " 'panama': 101,\n",
       " 'month': 102,\n",
       " 'country': 103,\n",
       " 'early': 104,\n",
       " 'letter': 105,\n",
       " 'increase': 106,\n",
       " 'business': 107,\n",
       " 'system': 108,\n",
       " 'saturday': 109,\n",
       " 'shot': 110,\n",
       " 'several': 111,\n",
       " 'group': 112,\n",
       " 'wednesday': 113,\n",
       " 'offer': 114,\n",
       " 'make': 115,\n",
       " 'think': 116,\n",
       " 'work': 117,\n",
       " 'earlier': 118,\n",
       " 'sunday': 119,\n",
       " 'want': 120,\n",
       " 'far': 121,\n",
       " 'past': 122,\n",
       " 'businesses': 123,\n",
       " 'week': 124,\n",
       " 'plan': 125,\n",
       " 'price': 126,\n",
       " 'magellan': 127,\n",
       " 'spacecraft': 128,\n",
       " 'contact': 129,\n",
       " 'employees': 130,\n",
       " 'polish': 131,\n",
       " 'study': 132,\n",
       " 'agents': 133,\n",
       " 'school': 134,\n",
       " 'spokesman': 135,\n",
       " 'outside': 136,\n",
       " 'least': 137,\n",
       " 'public': 138,\n",
       " 'plant': 139,\n",
       " 'even': 140,\n",
       " 'front': 141,\n",
       " 'security': 142,\n",
       " 'world': 143,\n",
       " 'operating': 144,\n",
       " 'continue': 145,\n",
       " 'talks': 146,\n",
       " 'help': 147,\n",
       " 'statement': 148,\n",
       " 'night': 149,\n",
       " 'lost': 150,\n",
       " 'service': 151,\n",
       " 'november': 152,\n",
       " 'inflation': 153,\n",
       " 'goods': 154,\n",
       " 'life': 155,\n",
       " 'average': 156,\n",
       " 'area': 157,\n",
       " 'services': 158,\n",
       " 'cuban': 159,\n",
       " 'head': 160,\n",
       " 'another': 161,\n",
       " 'four': 162,\n",
       " 'lot': 163,\n",
       " 'like': 164,\n",
       " 'found': 165,\n",
       " 'investigation': 166,\n",
       " 'minister': 167,\n",
       " 'come': 168,\n",
       " 'well': 169,\n",
       " 'liberace': 170,\n",
       " 'museum': 171,\n",
       " 'days': 172,\n",
       " 'called': 173,\n",
       " 'feet': 174,\n",
       " 'still': 175,\n",
       " 'got': 176,\n",
       " 'administration': 177,\n",
       " 'defense': 178,\n",
       " 'diplomatic': 179,\n",
       " 'democratic': 180,\n",
       " 'skins': 181,\n",
       " 'used': 182,\n",
       " 'support': 183,\n",
       " 'forest': 184,\n",
       " 'leader': 185,\n",
       " 'victims': 186,\n",
       " 'england': 187,\n",
       " 'production': 188,\n",
       " 'october': 189,\n",
       " 'john': 190,\n",
       " 'period': 191,\n",
       " 'second': 192,\n",
       " 'expected': 193,\n",
       " 'problems': 194,\n",
       " 'real': 195,\n",
       " 'agency': 196,\n",
       " 'blackowned': 197,\n",
       " 'teacher': 198,\n",
       " 'george': 199,\n",
       " 'family': 200,\n",
       " 'iraqi': 201,\n",
       " 'ministry': 202,\n",
       " 'san': 203,\n",
       " 'near': 204,\n",
       " 'relations': 205,\n",
       " 'came': 206,\n",
       " 'thats': 207,\n",
       " 'general': 208,\n",
       " 'political': 209,\n",
       " 'going': 210,\n",
       " 'way': 211,\n",
       " 'across': 212,\n",
       " 'york': 213,\n",
       " 'great': 214,\n",
       " 'following': 215,\n",
       " 'organization': 216,\n",
       " 'announced': 217,\n",
       " 'around': 218,\n",
       " 'started': 219,\n",
       " 'might': 220,\n",
       " 'im': 221,\n",
       " 'problem': 222,\n",
       " 'control': 223,\n",
       " 'taking': 224,\n",
       " 'committee': 225,\n",
       " 'miles': 226,\n",
       " '15': 227,\n",
       " 'six': 228,\n",
       " 'august': 229,\n",
       " 'increased': 230,\n",
       " 'annual': 231,\n",
       " 'nations': 232,\n",
       " 'pictures': 233,\n",
       " 'programs': 234,\n",
       " 'often': 235,\n",
       " 'commission': 236,\n",
       " 'arabia': 237,\n",
       " 'soviets': 238,\n",
       " 'arco': 239,\n",
       " 'guerrillas': 240,\n",
       " 'baker': 241,\n",
       " 'fbi': 242,\n",
       " 'films': 243,\n",
       " 'x': 244,\n",
       " 'apparently': 245,\n",
       " 'know': 246,\n",
       " 'students': 247,\n",
       " 'third': 248,\n",
       " 'primary': 249,\n",
       " 'bechtel': 250,\n",
       " 'israel': 251,\n",
       " 'rappaport': 252,\n",
       " 'never': 253,\n",
       " 'border': 254,\n",
       " 'asked': 255,\n",
       " 'according': 256,\n",
       " 'sales': 257,\n",
       " 'party': 258,\n",
       " 'become': 259,\n",
       " 'whether': 260,\n",
       " 'telephone': 261,\n",
       " 'late': 262,\n",
       " 'bloomberg': 263,\n",
       " 'including': 264,\n",
       " 'office': 265,\n",
       " 'car': 266,\n",
       " 'working': 267,\n",
       " 'away': 268,\n",
       " 'black': 269,\n",
       " 'began': 270,\n",
       " 'former': 271,\n",
       " 'star': 272,\n",
       " 'wife': 273,\n",
       " 'something': 274,\n",
       " 'theres': 275,\n",
       " 'brought': 276,\n",
       " 'reporters': 277,\n",
       " 'house': 278,\n",
       " 'international': 279,\n",
       " 'cuba': 280,\n",
       " 'syria': 281,\n",
       " 'department': 282,\n",
       " 'presidential': 283,\n",
       " 'efforts': 284,\n",
       " 'southern': 285,\n",
       " 'drug': 286,\n",
       " 'trade': 287,\n",
       " 'members': 288,\n",
       " 'leaders': 289,\n",
       " 'workers': 290,\n",
       " 'vote': 291,\n",
       " 'highest': 292,\n",
       " 'mayor': 293,\n",
       " 'governor': 294,\n",
       " 'republican': 295,\n",
       " 'reports': 296,\n",
       " 'industrial': 297,\n",
       " 'fear': 298,\n",
       " 'ferrets': 299,\n",
       " 'children': 300,\n",
       " 'doctors': 301,\n",
       " 'small': 302,\n",
       " 'compared': 303,\n",
       " 'talked': 304,\n",
       " 'set': 305,\n",
       " 'future': 306,\n",
       " 'biggest': 307,\n",
       " 'co': 308,\n",
       " 'change': 309,\n",
       " 'dog': 310,\n",
       " 'injured': 311,\n",
       " 'next': 312,\n",
       " 'tanks': 313,\n",
       " 'noted': 314,\n",
       " 'rebel': 315,\n",
       " 'worker': 316,\n",
       " 'communist': 317,\n",
       " 'europe': 318,\n",
       " 'need': 319,\n",
       " 'firefighters': 320,\n",
       " 'county': 321,\n",
       " 'orr': 322,\n",
       " 'czechoslovak': 323,\n",
       " 'ask': 324,\n",
       " 'iran': 325,\n",
       " 'survey': 326,\n",
       " 'hospital': 327,\n",
       " 'maxwell': 328,\n",
       " 'mpaa': 329,\n",
       " 'name': 330,\n",
       " 'identified': 331,\n",
       " '40': 332,\n",
       " 'serious': 333,\n",
       " 'condition': 334,\n",
       " 'door': 335,\n",
       " 'didnt': 336,\n",
       " 'appeared': 337,\n",
       " 'gun': 338,\n",
       " 'adult': 339,\n",
       " 'authorities': 340,\n",
       " 'senior': 341,\n",
       " 'offered': 342,\n",
       " 'without': 343,\n",
       " 'says': 344,\n",
       " 'things': 345,\n",
       " 'labor': 346,\n",
       " 'interested': 347,\n",
       " 'heard': 348,\n",
       " 'better': 349,\n",
       " 'music': 350,\n",
       " '2': 351,\n",
       " 'secretary': 352,\n",
       " 'number': 353,\n",
       " 'natural': 354,\n",
       " 'west': 355,\n",
       " 'reagan': 356,\n",
       " 'trouble': 357,\n",
       " 'powell': 358,\n",
       " 'within': 359,\n",
       " 'decision': 360,\n",
       " 'americans': 361,\n",
       " 'best': 362,\n",
       " 'senate': 363,\n",
       " 'call': 364,\n",
       " 'interests': 365,\n",
       " 'japan': 366,\n",
       " 'documents': 367,\n",
       " 'value': 368,\n",
       " 'toward': 369,\n",
       " 'election': 370,\n",
       " 'chairman': 371,\n",
       " 'career': 372,\n",
       " 'making': 373,\n",
       " 'issue': 374,\n",
       " 'increases': 375,\n",
       " 'manufacturing': 376,\n",
       " 'line': 377,\n",
       " 'caused': 378,\n",
       " 'given': 379,\n",
       " 'sen': 380,\n",
       " 'sometimes': 381,\n",
       " 'start': 382,\n",
       " 'based': 383,\n",
       " 'recent': 384,\n",
       " 'financial': 385,\n",
       " 'energy': 386,\n",
       " 'lay': 387,\n",
       " 'market': 388,\n",
       " 'earnings': 389,\n",
       " 'scientists': 390,\n",
       " 'venus': 391,\n",
       " 'earth': 392,\n",
       " 'radar': 393,\n",
       " 'bad': 394,\n",
       " 'details': 395,\n",
       " 'rebels': 396,\n",
       " 'agreement': 397,\n",
       " 'threat': 398,\n",
       " 'katyn': 399,\n",
       " 'tass': 400,\n",
       " 'moscow': 401,\n",
       " 'gasoline': 402,\n",
       " 'train': 403,\n",
       " 'site': 404,\n",
       " 'embassy': 405,\n",
       " 'director': 406,\n",
       " 'elephant': 407,\n",
       " 'hispanic': 408,\n",
       " 'societe': 409,\n",
       " 'tie': 410,\n",
       " 'shelter': 411,\n",
       " 'mcguire': 412,\n",
       " 'murder': 413,\n",
       " 'morning': 414,\n",
       " 'release': 415,\n",
       " 'boys': 416,\n",
       " 'jammed': 417,\n",
       " 'death': 418,\n",
       " 'wall': 419,\n",
       " 'complex': 420,\n",
       " 'high': 421,\n",
       " 'behind': 422,\n",
       " 'inc': 423,\n",
       " 'proposed': 424,\n",
       " 'pipeline': 425,\n",
       " '1': 426,\n",
       " 'point': 427,\n",
       " 'reached': 428,\n",
       " 'quoted': 429,\n",
       " 'memo': 430,\n",
       " 'robert': 431,\n",
       " 'denied': 432,\n",
       " 'go': 433,\n",
       " 'thought': 434,\n",
       " 'important': 435,\n",
       " 'put': 436,\n",
       " 'position': 437,\n",
       " 'concern': 438,\n",
       " 'took': 439,\n",
       " 'woman': 440,\n",
       " 'jewelry': 441,\n",
       " 'tried': 442,\n",
       " 'inside': 443,\n",
       " 'money': 444,\n",
       " 'place': 445,\n",
       " 'tied': 446,\n",
       " '29': 447,\n",
       " 'history': 448,\n",
       " 'upon': 449,\n",
       " 'pennsylvania': 450,\n",
       " 'penn': 451,\n",
       " 'invasion': 452,\n",
       " 'countries': 453,\n",
       " 'air': 454,\n",
       " 'force': 455,\n",
       " 'base': 456,\n",
       " 'court': 457,\n",
       " 'song': 458,\n",
       " 'sure': 459,\n",
       " 'hard': 460,\n",
       " 'enough': 461,\n",
       " 'panamanian': 462,\n",
       " 'foster': 463,\n",
       " 'operations': 464,\n",
       " 'central': 465,\n",
       " 'spokeswoman': 466,\n",
       " 'power': 467,\n",
       " 'later': 468,\n",
       " 'policies': 469,\n",
       " 'intelligence': 470,\n",
       " 'released': 471,\n",
       " 'export': 472,\n",
       " 'times': 473,\n",
       " 'plants': 474,\n",
       " 'half': 475,\n",
       " 'brush': 476,\n",
       " 'western': 477,\n",
       " 'stirbois': 478,\n",
       " 'capital': 479,\n",
       " 'ran': 480,\n",
       " 'member': 481,\n",
       " '1977': 482,\n",
       " 'deputy': 483,\n",
       " 'worst': 484,\n",
       " 'cant': 485,\n",
       " 'awards': 486,\n",
       " 'together': 487,\n",
       " '17': 488,\n",
       " 'robb': 489,\n",
       " 'level': 490,\n",
       " 'responsibility': 491,\n",
       " 'major': 492,\n",
       " 'troubles': 493,\n",
       " 'rise': 494,\n",
       " 'index': 495,\n",
       " 'sector': 496,\n",
       " 'higher': 497,\n",
       " 'spending': 498,\n",
       " '04': 499,\n",
       " 'say': 500,\n",
       " 'health': 501,\n",
       " 'sale': 502,\n",
       " 'north': 503,\n",
       " 'strait': 504,\n",
       " 'award': 505,\n",
       " 'much': 506,\n",
       " 'cut': 507,\n",
       " 'language': 508,\n",
       " 'houston': 509,\n",
       " 'evening': 510,\n",
       " 'peace': 511,\n",
       " 'various': 512,\n",
       " 'different': 513,\n",
       " 'lead': 514,\n",
       " 'enron': 515,\n",
       " 'largest': 516,\n",
       " 'per': 517,\n",
       " 'assets': 518,\n",
       " 'signal': 519,\n",
       " 'loss': 520,\n",
       " 'however': 521,\n",
       " 'face': 522,\n",
       " 'april': 523,\n",
       " 'words': 524,\n",
       " 'others': 525,\n",
       " 'costs': 526,\n",
       " 'loans': 527,\n",
       " 'difficult': 528,\n",
       " 'island': 529,\n",
       " 'order': 530,\n",
       " 'ground': 531,\n",
       " 'heavy': 532,\n",
       " 'numbers': 533,\n",
       " 'ortega': 534,\n",
       " 'overall': 535,\n",
       " 'sides': 536,\n",
       " 'contra': 537,\n",
       " 'ii': 538,\n",
       " 'graves': 539,\n",
       " 'nkvd': 540,\n",
       " 'speech': 541,\n",
       " 'truth': 542,\n",
       " 'chemical': 543,\n",
       " 'judge': 544,\n",
       " 'consumer': 545,\n",
       " 'less': 546,\n",
       " 'pittsburgh': 547,\n",
       " 'arms': 548,\n",
       " 'enforcement': 549,\n",
       " 'acres': 550,\n",
       " 'seen': 551,\n",
       " 'source': 552,\n",
       " 'gallon': 553,\n",
       " 'reforms': 554,\n",
       " 'firms': 555,\n",
       " 'zoo': 556,\n",
       " 'bombs': 557,\n",
       " 'generale': 558,\n",
       " 'classroom': 559,\n",
       " 'atlantic': 560,\n",
       " 'attempted': 561,\n",
       " 'assault': 562,\n",
       " 'related': 563,\n",
       " 'friends': 564,\n",
       " 'boy': 565,\n",
       " 'talking': 566,\n",
       " 'knew': 567,\n",
       " 'little': 568,\n",
       " '22': 569,\n",
       " 'nothing': 570,\n",
       " 'big': 571,\n",
       " 'h': 572,\n",
       " 'meeting': 573,\n",
       " 'thurston': 574,\n",
       " 'chief': 575,\n",
       " 'charles': 576,\n",
       " 'spent': 577,\n",
       " 'whose': 578,\n",
       " 'building': 579,\n",
       " 'trying': 580,\n",
       " '1985': 581,\n",
       " 'promised': 582,\n",
       " 'anonymity': 583,\n",
       " 'acknowledged': 584,\n",
       " 'planned': 585,\n",
       " 'francisco': 586,\n",
       " 'vice': 587,\n",
       " 'swiss': 588,\n",
       " 'development': 589,\n",
       " 'project': 590,\n",
       " 'anything': 591,\n",
       " 'proposals': 592,\n",
       " 'believed': 593,\n",
       " 'speaking': 594,\n",
       " 'sources': 595,\n",
       " 'secret': 596,\n",
       " 'thing': 597,\n",
       " 'person': 598,\n",
       " 'town': 599,\n",
       " 'comment': 600,\n",
       " 'gunman': 601,\n",
       " 'hostage': 602,\n",
       " 'case': 603,\n",
       " 'produced': 604,\n",
       " 'refused': 605,\n",
       " 'receipts': 606,\n",
       " 'cash': 607,\n",
       " 'hands': 608,\n",
       " 'moved': 609,\n",
       " 'getting': 610,\n",
       " 'due': 611,\n",
       " 'oct': 612,\n",
       " 'todays': 613,\n",
       " 'stock': 614,\n",
       " 'exchange': 615,\n",
       " 'thousands': 616,\n",
       " 'turkey': 617,\n",
       " 'men': 618,\n",
       " 'convicted': 619,\n",
       " 'women': 620,\n",
       " '1986': 621,\n",
       " 'right': 622,\n",
       " '23': 623,\n",
       " 'arrived': 624,\n",
       " 'actor': 625,\n",
       " 'valentines': 626,\n",
       " 'send': 627,\n",
       " '50': 628,\n",
       " '14': 629,\n",
       " 'law': 630,\n",
       " 'tax': 631,\n",
       " 'payments': 632,\n",
       " 'sanctions': 633,\n",
       " 'yet': 634,\n",
       " 'pressure': 635,\n",
       " 'remove': 636,\n",
       " 'white': 637,\n",
       " 'provide': 638,\n",
       " 'immediate': 639,\n",
       " 'troops': 640,\n",
       " 'living': 641,\n",
       " 'view': 642,\n",
       " 'sent': 643,\n",
       " 'weeks': 644,\n",
       " 'congress': 645,\n",
       " 'soldiers': 646,\n",
       " 'established': 647,\n",
       " 'seven': 648,\n",
       " 'south': 649,\n",
       " 'retail': 650,\n",
       " 'required': 651,\n",
       " 'animals': 652,\n",
       " 'illegal': 653,\n",
       " 'especially': 654,\n",
       " 'candidate': 655,\n",
       " 'michael': 656,\n",
       " 'nominee': 657,\n",
       " 'votes': 658,\n",
       " 'nearly': 659,\n",
       " 'leadership': 660,\n",
       " '1982': 661,\n",
       " 'percentage': 662,\n",
       " 'jobs': 663,\n",
       " 'lived': 664,\n",
       " 'camps': 665,\n",
       " 'eastern': 666,\n",
       " 'sang': 667,\n",
       " 'drood': 668,\n",
       " 'daughter': 669,\n",
       " 'johnson': 670,\n",
       " 'strong': 671,\n",
       " 'gains': 672,\n",
       " 'education': 673,\n",
       " 'strength': 674,\n",
       " 'attention': 675,\n",
       " 'society': 676,\n",
       " 'note': 677,\n",
       " 'considering': 678,\n",
       " 'factories': 679,\n",
       " 'utilities': 680,\n",
       " 'nine': 681,\n",
       " 'likely': 682,\n",
       " 'board': 683,\n",
       " 'capacity': 684,\n",
       " '05': 685,\n",
       " 'reflecting': 686,\n",
       " 'light': 687,\n",
       " 'equipment': 688,\n",
       " 'particularly': 689,\n",
       " 'lower': 690,\n",
       " 'declined': 691,\n",
       " 'output': 692,\n",
       " 'total': 693,\n",
       " 'bites': 694,\n",
       " 'university': 695,\n",
       " 'although': 696,\n",
       " 'tour': 697,\n",
       " 'mind': 698,\n",
       " 'wont': 699,\n",
       " 'double': 700,\n",
       " 'visited': 701,\n",
       " 'un': 702,\n",
       " 'final': 703,\n",
       " 'crowd': 704,\n",
       " 'deep': 705,\n",
       " 'holding': 706,\n",
       " 'calling': 707,\n",
       " 'immediately': 708,\n",
       " 'interview': 709,\n",
       " 'current': 710,\n",
       " 'reduction': 711,\n",
       " 'quarter': 712,\n",
       " 'among': 713,\n",
       " 'income': 714,\n",
       " 'test': 715,\n",
       " 'manager': 716,\n",
       " 'hear': 717,\n",
       " 'find': 718,\n",
       " 'space': 719,\n",
       " 'jim': 720,\n",
       " 'previous': 721,\n",
       " 'stations': 722,\n",
       " 'turned': 723,\n",
       " 'garbo': 724,\n",
       " 'finally': 725,\n",
       " 'book': 726,\n",
       " 'tells': 727,\n",
       " 'cuts': 728,\n",
       " 'assistance': 729,\n",
       " 'largely': 730,\n",
       " 'named': 731,\n",
       " 'march': 732,\n",
       " 'needs': 733,\n",
       " 'measures': 734,\n",
       " 'signed': 735,\n",
       " 'boston': 736,\n",
       " 'large': 737,\n",
       " 'lawsuit': 738,\n",
       " 'arab': 739,\n",
       " 'm1s': 740,\n",
       " 'primarily': 741,\n",
       " 'considered': 742,\n",
       " 'weapons': 743,\n",
       " 'bring': 744,\n",
       " 'weve': 745,\n",
       " 'sandinista': 746,\n",
       " 'governments': 747,\n",
       " 'agreed': 748,\n",
       " 'bermudez': 749,\n",
       " 'civilian': 750,\n",
       " 'issued': 751,\n",
       " 'havana': 752,\n",
       " 'mexico': 753,\n",
       " 'stalin': 754,\n",
       " 'massacre': 755,\n",
       " 'blamed': 756,\n",
       " 'captured': 757,\n",
       " 'beginning': 758,\n",
       " 'east': 759,\n",
       " 'jaruzelski': 760,\n",
       " 'regret': 761,\n",
       " '25': 762,\n",
       " 'live': 763,\n",
       " 'changes': 764,\n",
       " 'angeles': 765,\n",
       " 'sorgenti': 766,\n",
       " 'exploded': 767,\n",
       " 'lose': 768,\n",
       " 'pounds': 769,\n",
       " 'benefits': 770,\n",
       " 'street': 771,\n",
       " 'flying': 772,\n",
       " 'aircraft': 773,\n",
       " 'homeless': 774,\n",
       " 'cattle': 775,\n",
       " 'trees': 776,\n",
       " 'el': 777,\n",
       " 'harvard': 778,\n",
       " 'armed': 779,\n",
       " 'radioactive': 780,\n",
       " 'nuclear': 781,\n",
       " 'nelson': 782,\n",
       " 'ctk': 783,\n",
       " 'dramatic': 784,\n",
       " 'june': 785,\n",
       " 'regular': 786,\n",
       " 'unleaded': 787,\n",
       " 'grew': 788,\n",
       " 'hispanics': 789,\n",
       " 'fbis': 790,\n",
       " 'testified': 791,\n",
       " 'petition': 792,\n",
       " 'film': 793,\n",
       " 'student': 794,\n",
       " 'private': 795,\n",
       " 'arrested': 796,\n",
       " 'relatives': 797,\n",
       " 'save': 798,\n",
       " 'troubled': 799,\n",
       " 'guns': 800,\n",
       " 'always': 801,\n",
       " '32': 802,\n",
       " 'marino': 803,\n",
       " 'wounds': 804,\n",
       " 'running': 805,\n",
       " 'glass': 806,\n",
       " 'locked': 807,\n",
       " 'carried': 808,\n",
       " 'adding': 809,\n",
       " 'bureau': 810,\n",
       " '500': 811,\n",
       " 'body': 812,\n",
       " 'ms': 813,\n",
       " 'hour': 814,\n",
       " 'sell': 815,\n",
       " 'bomb': 816,\n",
       " 'assurances': 817,\n",
       " 'run': 818,\n",
       " 'include': 819,\n",
       " 'israeli': 820,\n",
       " 'post': 821,\n",
       " 'close': 822,\n",
       " 'keep': 823,\n",
       " 'sees': 824,\n",
       " 'every': 825,\n",
       " 'attorney': 826,\n",
       " 'meese': 827,\n",
       " 'referred': 828,\n",
       " 'arrangement': 829,\n",
       " 'receive': 830,\n",
       " 'friend': 831,\n",
       " 'indicated': 832,\n",
       " 'able': 833,\n",
       " 'attempt': 834,\n",
       " 'margaret': 835,\n",
       " 'sat': 836,\n",
       " 'give': 837,\n",
       " 'entertainer': 838,\n",
       " 'wanted': 839,\n",
       " 'worked': 840,\n",
       " 'closing': 841,\n",
       " 'wasnt': 842,\n",
       " 'seemed': 843,\n",
       " 'walked': 844,\n",
       " 'collapsed': 845,\n",
       " 'las': 846,\n",
       " 'record': 847,\n",
       " 'systems': 848,\n",
       " 'founded': 849,\n",
       " '1988': 850,\n",
       " 'local': 851,\n",
       " 'william': 852,\n",
       " 'drew': 853,\n",
       " 'launched': 854,\n",
       " 'television': 855,\n",
       " 'india': 856,\n",
       " '43': 857,\n",
       " 'richard': 858,\n",
       " 'actress': 859,\n",
       " 'modern': 860,\n",
       " 'word': 861,\n",
       " 'verse': 862,\n",
       " 'estimated': 863,\n",
       " 'latest': 864,\n",
       " 'perhaps': 865,\n",
       " 'recently': 866,\n",
       " 'takes': 867,\n",
       " 'born': 868,\n",
       " '300': 869,\n",
       " '7': 870,\n",
       " 'charge': 871,\n",
       " 'touch': 872,\n",
       " 'examining': 873,\n",
       " 'bear': 874,\n",
       " 'situation': 875,\n",
       " 'corporations': 876,\n",
       " 'act': 877,\n",
       " 'cautious': 878,\n",
       " 'army': 879,\n",
       " 'believes': 880,\n",
       " 'jesse': 881,\n",
       " 'jacksons': 882,\n",
       " 'despite': 883,\n",
       " 'communications': 884,\n",
       " 'channels': 885,\n",
       " 'tactic': 886,\n",
       " 'buy': 887,\n",
       " 'available': 888,\n",
       " 'traveling': 889,\n",
       " 'california': 890,\n",
       " 'candidates': 891,\n",
       " 'dealing': 892,\n",
       " 'earned': 893,\n",
       " 'plans': 894,\n",
       " 'try': 895,\n",
       " '10000': 896,\n",
       " 'probably': 897,\n",
       " 'evidence': 898,\n",
       " 'jose': 899,\n",
       " 'offices': 900,\n",
       " 'costa': 901,\n",
       " 'step': 902,\n",
       " 'renewed': 903,\n",
       " 'leave': 904,\n",
       " 'remain': 905,\n",
       " 'caiman': 906,\n",
       " 'involving': 907,\n",
       " 'thailand': 908,\n",
       " 'onto': 909,\n",
       " 'cites': 910,\n",
       " 'allowed': 911,\n",
       " 'industry': 912,\n",
       " 'unless': 913,\n",
       " 'improvement': 914,\n",
       " 'organized': 915,\n",
       " 'boost': 916,\n",
       " 'single': 917,\n",
       " 'almost': 918,\n",
       " 'appears': 919,\n",
       " 'fires': 920,\n",
       " 'le': 921,\n",
       " 'pen': 922,\n",
       " 'automobile': 923,\n",
       " 'paris': 924,\n",
       " '1981': 925,\n",
       " '30': 926,\n",
       " 'elections': 927,\n",
       " 'district': 928,\n",
       " 'citizens': 929,\n",
       " 'affected': 930,\n",
       " 'homes': 931,\n",
       " 'southwest': 932,\n",
       " 'newspapers': 933,\n",
       " 'standards': 934,\n",
       " 'tony': 935,\n",
       " 'fair': 936,\n",
       " 'jack': 937,\n",
       " 'failed': 938,\n",
       " 'ever': 939,\n",
       " 'planet': 940,\n",
       " 'dogs': 941,\n",
       " 'anyone': 942,\n",
       " 'huge': 943,\n",
       " 'success': 944,\n",
       " 'democrats': 945,\n",
       " 'known': 946,\n",
       " 'social': 947,\n",
       " 'race': 948,\n",
       " 'popular': 949,\n",
       " 'collective': 950,\n",
       " 'job': 951,\n",
       " 'iraqs': 952,\n",
       " 'concluded': 953,\n",
       " 'mines': 954,\n",
       " 'reserve': 955,\n",
       " 'points': 956,\n",
       " 'eight': 957,\n",
       " 'economists': 958,\n",
       " 'leading': 959,\n",
       " 'truck': 960,\n",
       " 'rates': 961,\n",
       " 'december': 962,\n",
       " 'parts': 963,\n",
       " 'consecutive': 964,\n",
       " 'includes': 965,\n",
       " 'reserves': 966,\n",
       " 'accompanied': 967,\n",
       " 'stronger': 968,\n",
       " '06': 969,\n",
       " 'stood': 970,\n",
       " 'increasingly': 971,\n",
       " 'pets': 972,\n",
       " 'attacks': 973,\n",
       " 'bitten': 974,\n",
       " '39': 975,\n",
       " 'claim': 976,\n",
       " 'buying': 977,\n",
       " 'injuries': 978,\n",
       " 'described': 979,\n",
       " 'arizona': 980,\n",
       " 'population': 981,\n",
       " '03': 982,\n",
       " 'georgia': 983,\n",
       " 'ceremony': 984,\n",
       " 'stop': 985,\n",
       " 'return': 986,\n",
       " 'means': 987,\n",
       " 'longer': 988,\n",
       " 'crystal': 989,\n",
       " 'vocal': 990,\n",
       " 'ford': 991,\n",
       " 'consider': 992,\n",
       " 'normally': 993,\n",
       " 'husband': 994,\n",
       " 'received': 995,\n",
       " 'felt': 996,\n",
       " 'nervous': 997,\n",
       " 'ended': 998,\n",
       " 'referendum': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_model.word2Idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Domains Affect Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 5.7178974151611327e-05\n",
      "torch.Size([1000, 1])\n",
      "avg time: 2.7730941772460937e-05\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "w1 = nn.Parameter(torch.randn(1000, 100).float(), requires_grad=True)\n",
    "w2 = nn.Parameter(torch.randn(1000,  100).float(), requires_grad=True)\n",
    "nIters = 1000\n",
    "negSampleSize = 1000\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    temp = torch.mm(w2[0:negSampleSize], torch.t(w2[0].view(1, -1)))\n",
    "print(\"avg time: {}\".format((time.time() - start)/nIters))\n",
    "print(temp.shape)\n",
    "\n",
    "\n",
    "\n",
    "w1 = w1.data.numpy()\n",
    "w2 = w2.data.numpy()\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    temp = np.matmul(w2[0:negSampleSize], w1[0])\n",
    "print(\"avg time: {}\".format((time.time() - start)/nIters))\n",
    "print(temp.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg time: 3.156447410583496e-05\n",
      "torch.Size([15, 1])\n",
      "avg time: 5.325794219970703e-06\n",
      "(15,)\n"
     ]
    }
   ],
   "source": [
    "w1 = nn.Parameter(torch.randn(1000, 100).float(), requires_grad=True)\n",
    "w2 = nn.Parameter(torch.randn(1000,  100).float(), requires_grad=True)\n",
    "nIters = 1000\n",
    "negSampleSize = 15\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    temp = torch.mm(w2[0:negSampleSize], torch.t(w2[0].view(1, -1)))\n",
    "print(\"avg time: {}\".format((time.time() - start)/nIters))\n",
    "print(temp.shape)\n",
    "\n",
    "\n",
    "\n",
    "w1 = w1.data.numpy()\n",
    "w2 = w2.data.numpy()\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    temp = np.matmul(w2[0:negSampleSize], w1[0])\n",
    "print(\"avg time: {}\".format((time.time() - start)/nIters))\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = w1.data.numpy()\n",
    "w2 = w2.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(w2[0:15], w1[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first',\n",
       "  'quit',\n",
       "  'grinnin',\n",
       "  'like',\n",
       "  'idiot',\n",
       "  'indians',\n",
       "  'aint',\n",
       "  'supposed',\n",
       "  'smile',\n",
       "  'like',\n",
       "  'get',\n",
       "  'stoic'],\n",
       " ['like', 'gotta', 'look', 'mean', 'people', 'wont', 'respect'],\n",
       " ['people', 'run', 'dont', 'look', 'mean'],\n",
       " ['gotta',\n",
       "  'look',\n",
       "  'like',\n",
       "  'warrior',\n",
       "  'gotta',\n",
       "  'look',\n",
       "  'like',\n",
       "  'came',\n",
       "  'back',\n",
       "  'killing',\n",
       "  'buffalo'],\n",
       " ['tribe',\n",
       "  'never',\n",
       "  'hunted',\n",
       "  'buffalo',\n",
       "  'fishermenwhat',\n",
       "  'wanna',\n",
       "  'look',\n",
       "  'like',\n",
       "  'came',\n",
       "  'back',\n",
       "  'catching',\n",
       "  'fish'],\n",
       " ['aint',\n",
       "  'dances',\n",
       "  'salmon',\n",
       "  'know',\n",
       "  'thomas',\n",
       "  'gotta',\n",
       "  'look',\n",
       "  'like',\n",
       "  'warrior']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTokenizedCorpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Computational Methods)",
   "language": "python",
   "name": "computational_methods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
